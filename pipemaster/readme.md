This directory holds the information for running the program pipemaster to perform demographic modeling. For this manuscript, we designed a custom pipeline for creating the demographic models, tweaking/optimizing prior distributions for key parameters, and rigorously implementing the simulation and model selection approach. The details of each of these steps are outlined below:

## 1: Setting up demographic models
- The approach to setting up models in pipemaster can be challenging. Essentially the best approach is just to familiarize yourself with the overall structure of the model object, and manipulate it manually in R until you have the exact model and set of priors you want. Regularly using the PlotModel() function from the PipeMaster R package is key to making sure that you are actually setting up the model you're interested in correctly. For this dataset, example code outlining how I set up the four models I was interested in can be found at: [https://devonderaad.github.io/phil.dicaeum.rad/pipemaster/set.up.models.html](https://devonderaad.github.io/phil.dicaeum.rad/pipemaster/set.up.models.html). Each of the models used in the manuscript can be directly downloaded from this repository (files 'm1.txt', 'm2.txt', 'm3.txt', and 'm4.txt'). You can read these models into R using the dget() command, and modify them to fit your datasets or use them to validate our results. The file '2188.whitelist.txt' has the list of loci we used, and 'PM.popmap.txt' has the list of all samples included. The file 'popassign.csv' assigns the 58 individuals included into the analysis into the three distinct populations we modeled.

## 2: Optimizing/tweaking prior distributions
- After setting up these four models, we performed a preliminary round of parameter optimization, where we assessed the fit of our models to the empirical dataset and iteratively tweaked the parameters Ne and divergence time in an attempt to center our emprical dataset within the parameter space of the simulated models using the parameters Fst, Pi, and # of segregating sites to determine best fit. We observed that these efforts improved the fit of our models to the data, yet some parameters were still poorly estimated, with the range of all four models well outside of our observed data. To ameliorate this, we performed a one-sample t-test to generate a t-statistic quantifying the likelihood of our observed data coming from the set of models for all 82 estimated parameters. We then used this t-statistic value to remove the bottom quartile (here 20 variables) of variables that predicted our observed data most poorly. Add more details
https://devonderaad.github.io/phil.dicaeum.rad/pipemaster/preliminary.parameter.optimization.html

## 3: Running the entire simulation and model selection process in replicate
-
